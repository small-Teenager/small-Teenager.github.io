[{"title":"如何应对接口机故障","url":"%2F2019%2F11%2F04%2F%E5%A6%82%E4%BD%95%E5%BA%94%E5%AF%B9%E6%8E%A5%E5%8F%A3%E7%BA%A7%E6%95%85%E9%9A%9C%2F","content":"\n\n* 接口级故障的典型表现就是系统并没有宕机，网络也没有中断，但业务却出现了问题。例\n如，业务响应缓慢、大量访问超时、大量访问出现异常（给用户弹出提示“无法连接数据\n库”），这类问题的主要原因在于系统压力过大、负载太高，导致无法快速处理业务请求，\n由此引发更多的后续问题。例如，最常见的数据库慢查询将数据库的服务器资源耗尽，导致\n读写超时，业务读写数据库时要么无法连接数据库、要么超时，最终用户看到的现象就是访\n问很慢，一会访问抛出异常，一会访问又是正常结果。\n\n\n## 导致接口级故障的原因一般有下面几种：\n\n### 内部原因\n\n* 程序 bug 导致死循环，某个接口导致数据库慢查询，程序逻辑不完善导致耗尽内存等。\n\n### 外部原因\n\n* 黑客攻击、促销或者抢购引入了超出平时几倍甚至几十倍的用户，第三方系统大量请求，第\n三方系统响应缓慢等。\n\n### 解决接口级故障的核心思想\n\n* 优先保证核心业务和优先保证绝大部分用户\n\n## 降级\n\n* 降级指系统将某些业务或者接口的功能降低，可以是只提供部分功能，也可以是完全停掉所\n有功能。例如，论坛可以降级为只能看帖子，不能发帖子；也可以降级为只能看帖子和评\n论，不能发评论；而 App 的日志上传接口，可以完全停掉一段时间，这段时间内 App 都\n不能上传日志。\n\n* 降级的核心思想就是丢车保帅，优先保证核心业务。例如，对于论坛来说，90% 的流量是\n看帖子，那我们就优先保证看帖的功能；对于一个 App 来说，日志上传接口只是一个辅助\n的功能，故障时完全可以停掉。\n\n* 常见的实现降级的方式有：\n简单来说，就是系统预留了后门用于降级操作。例如，系统提供一个降级 URL，当访问这\n个 URL 时，就相当于执行降级指令，具体的降级指令通过 URL 的参数传入即可。这种方\n案有一定的安全隐患，所以也会在 URL 中加入密码这类安全措施。\n系统后门降级的方式实现成本低，但主要缺点是如果服务器数量多，需要一台一台去操作，\n效率比较低，这在故障处理争分夺秒的场景下是比较浪费时间的。\n\n## 熔断\n\n* 熔断和降级是两个比较容易混淆的概念，因为单纯从名字上看好像都有禁止某个功能的意\n思，但其实内在含义是不同的，原因在于降级的目的是应对系统自身的故障，而熔断的目的\n是应对依赖的外部系统故障的情况。\n\n* 假设一个这样的场景：A 服务的 X 功能依赖 B 服务的某个接口，当 B 服务的接口响应很慢\n的时候，A 服务的 X 功能响应肯定也会被拖慢，进一步导致 A 服务的线程都被卡在 X 功能\n处理上，此时 A 服务的其他功能都会被卡住或者响应非常慢。这时就需要熔断机制了，\n即：A 服务不再请求 B 服务的这个接口，A 服务内部只要发现是请求 B 服务的这个接口就\n立即返回错误，从而避免 A 服务整个被拖慢甚至拖死。\n\n* 熔断机制实现的关键是需要有一个统一的 API 调用层，由 API 调用层来进行采样或者统\n计，如果接口调用散落在代码各处就没法进行统一处理了。\n\n* 熔断机制实现的另外一个关键是阈值的设计，例如 1 分钟内 30% 的请求响应时间超过 1\n秒就熔断，这个策略中的“1 分钟”“30%”“1 秒”都对最终的熔断效果有影响。\n\n\n## 限流\n\n* 降级是从系统功能优先级的角度考虑如何应对故障，而限流则是从用户访问压力的角度来考\n虑如何应对故障。限流指只允许系统能够承受的访问量进来，超出系统访问能力的请求将被\n丢弃。\n\n* 虽然“丢弃”这个词听起来让人不太舒服，但保证一部分请求能够正常响应，总比全部请求\n都不能响应要好得多。\n\n* 限流一般都是系统内实现的，常见的限流方式可以分为两类：基于请求限流和基于资源限\n流。\n\n* 基于请求限流指从外部访问的请求角度考虑限流，常见的方式有：限制总量、限制时间量。\n限制总量的方式是限制某个指标的累积上限，常见的是限制当前系统服务的用户总量，例如\n某个直播间限制总用户数上限为 100 万，超过 100 万后新的用户无法进入；某个抢购活动\n商品数量只有 100 个，限制参与抢购的用户上限为 1 万个，1 万以后的用户直接拒绝。限\n制时间量指限制一段时间内某个指标的上限，例如，1 分钟内只允许 10000 个用户访问，\n每秒请求峰值最高为 10 万。\n\n* 无论是限制总量还是限制时间量，共同的特点都是实现简单，但在实践中面临的主要问题是\n比较难以找到合适的阈值，例如系统设定了 1 分钟 10000 个用户，但实际上 6000 个用户\n的时候系统就扛不住了；也可能达到 1 分钟 10000 用户后，其实系统压力还不大，但此时\n已经开始丢弃用户访问了。\n\n* 即使找到了合适的阈值，基于请求限流还面临硬件相关的问题。例如一台 32 核的机器和\n64 核的机器处理能力差别很大，阈值是不同的，可能有的技术人员以为简单根据硬件指标\n进行数学运算就可以得出来，实际上这样是不可行的，64 核的机器比 32 核的机器，业务\n处理性能并不是 2 倍的关系，可能是 1.5 倍，甚至可能是 1.1 倍。\n\n* 为了找到合理的阈值，通常情况下可以采用性能压测来确定阈值，但性能压测也存在覆盖场\n景有限的问题，可能出现某个性能压测没有覆盖的功能导致系统压力很大；另外一种方式是\n基于请求限流\n限制总量的方式是限制某个指标的累积上限，常见的是限制当前系统服务的用户总量，例如\n某个直播间限制总用户数上限为 100 万，超过 100 万后新的用户无法进入；某个抢购活动\n商品数量只有 100 个，限制参与抢购的用户上限为 1 万个，1 万以后的用户直接拒绝。限\n制时间量指限制一段时间内某个指标的上限，例如，1 分钟内只允许 10000 个用户访问，\n每秒请求峰值最高为 10 万。\n\n\n## 排队\n\n* 排队实际上是限流的一个变种，限流是直接拒绝用户，排队是让用户等待一段时间，全世界\n最有名的排队当属 12306 网站排队了。排队虽然没有直接拒绝用户，但用户等了很长时间\n后进入系统，体验并不一定比限流好。\n* 由于排队需要临时缓存大量的业务请求，单个系统内部无法缓存这么多数据，一般情况下，\n排队需要用独立的系统去实现。","tags":["架构"]},{"title":"jpa 常用注解","url":"%2F2019%2F09%2F22%2Fjpa-%E5%B8%B8%E7%94%A8%E6%B3%A8%E8%A7%A3%2F","content":"\n`````````\n\nimport org.springframework.data.annotation.CreatedDate;\nimport org.springframework.data.annotation.LastModifiedDate;\nimport org.springframework.data.jpa.domain.support.AuditingEntityListener;\n\nimport javax.persistence.Column;\nimport javax.persistence.Entity;\nimport javax.persistence.EntityListeners;\nimport java.io.Serializable;\nimport java.time.LocalDateTime;\n//Spring Data JPA 的时间注解\n/**\n * @author Search\n * @version 1.0\n * @date 2019/9/2 10:25\n */\n@Entity\n@EntityListeners(AuditingEntityListener.class)\npublic class Base implements Serializable {\n\t\n\t//选择 Spring Data JPA 框架开发时，常用在实体和字段上的注解有@Entity、@Id、@Column等。在表设计规范中，通常建议保留的有两个字段，一个是更新时间，一个是创建时间。Spring Data JPA 提供了相应的时间注解，只需要两步配置，就可以帮助开发者快速实现这方面的功能。\n\n//在实体类上加上注解 @EntityListeners(AuditingEntityListener.class)，在相应的字段上添加对应的时间注解 @LastModifiedDate 和 @CreatedDate\n\n//日期类型可以用 Date 也可以是 Long\n\n    private static final long serialVersionUID = 7297611707550474985L;\n\n\t@Id\n\tprivate String id;//ID\n\n    /**\n     * 更新时间 日期类型可以是 Long\n     */\n    @LastModifiedDate\n    @Column(name = \"update_time\",nullable = false)\n    private LocalDateTime updateTime;\n\n    /**\n     * 创建时间 日期类型可以是 Long\n\t * name 对应数据库中字段名\n\t * updatable = false 更新数据时不更新该字段\n\t * nullable = false 数据库中不允许为null\n     */\n    @CreatedDate\n    @Column(name = \"create_time\",updatable = false, nullable = false)\n    private LocalDateTime createTime;\n\n\t\n}\n2//启动类添加  @EnableJpaAuditing\n\n在Application启动类中添加注解 @EnableJpaAuditing\n@EnableJpaAuditing\n@SpringBootApplication\npublic class Application {\n\n    public static void main(String[] args) {\n        SpringApplication.run(Application.class, args);\n    }\n    \n}\n\n\nspring 注解验证 常用标签\n\n@Null  被注释的元素必须为null\n@NotNull  被注释的元素不能为null\n@NotEmpty  被注释的字符串必须非空\n@AssertTrue  被注释的元素必须为true\n@AssertFalse  被注释的元素必须为false\n@Length 被注释的字符串的大小必须在指定的范围内 \n@Digits(integer,fraction)  被注释的元素必须是一个数字，其值必须在可接受的范围内\n@Min(value)  被注释的元素必须是一个数字，其值必须大于等于指定的最小值\n@Max(value)  被注释的元素必须是一个数字，其值必须小于等于指定的最大值\n@DecimalMin(value)  被注释的元素必须是一个数字，其值必须大于等于指定的最小值\n@DecimalMax(value)  被注释的元素必须是一个数字，其值必须小于等于指定的最大值\n@Size(max,min)  被注释的元素的大小必须在指定的范围内。\n@Past  被注释的元素必须是一个过去的日期\n@Future  被注释的元素必须是一个将来的日期\n@Pattern(value) 被注释的元素必须符合指定的正则表达式。\n@Email 被注释的元素必须是电子邮件地址\n@Range  被注释的元素必须在合适的范围内\n@URL(protocol=,host,port) 检查是否是一个有效的URL,如果提供了protocol,host等，则该URL还需满足提供的条件\n\n\n\n\nSpringBoot的Web组件内部集成了hibernate-validator，所以我们这里并不需要额外的为验证再导入其他的包，接下来我们先来看看SpringBoot为我们提供了哪些验证。\n\n内置验证\nSpringBoot因为采用了hibernate-validator，所以我们直接使用hibernate-validator就可以进行数据校验\n\n\n\n````````"},{"title":"父子节点的List转 tree","url":"%2F2019%2F08%2F30%2F%E7%88%B6%E5%AD%90%E8%8A%82%E7%82%B9%E7%9A%84List%E8%BD%AC-tree%2F","content":"> 摘要： 本文主要介绍父子节点的List转 tree\n\n``````\n\n1、构建tree\n2、从数据库查询list\n3、将list转为tree\n \n/**\n * 树节点实体类\n */\n@Data\npublic class TreeNode implements Serializable {\n\n\tprivate static final long serialVersionUID = 7297611707550474985L;\n\t\n\tprivate Integer id;\n\t\n\tprivate Integer parentId;\n\t\n\tprivate String name;\n\t\n\tprivate List<TreeNode> children;\n\t\n\tpublic TreeNode(String id, String name, String parentId) {\n\t\tthis.id = id;\n\t\tthis.parentId = parentId;\n\t\tthis.name = name;\n\t}\n}\n\t\n\t\t\n\t// 根节点\n\tprivate final Integer PARENT_ID=0;\n\n\t/**\n\t * 方式一：使用for循环实现\n\t * @param treeList\n\t * @return\n\t */\n\tprivate List<TreeNode> loopToTree(List<TreeNode> treeList) {\n\t\tList<TreeNode> resList = new ArrayList<>();\n\t\t\n\t\tfor (TreeNode parent : treeList) {\n\t\t\t//添加根节点\n\t\t\tif (PARENT_ID==parent.getParentId()) {\n\t\t\t\tresList.add(parent);\n\t\t\t}\n\t\t\t//添加子节点\n\t\t\tfor (TreeNode child : treeList) {\n\t\t\t\tif (child.getParentId() == parent.getId()) {\n\t\t\t\t\tif (parent.getChildren() == null) {\n\t\t\t\t\t\tparent.setChildren(new ArrayList<>());\n\t\t\t\t\t}\n\t\t\t\t\tparent.getChildren().add(child);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn resList;\n\t}\n\n\n\t/**\n\t * 方式二：使用递归实现\n\t * @param treeList\n\t * @return\n\t */\n\tprivate  List<TreeNode> recursionToTree(List<TreeNode> treeList) {\n\t\tList<TreeNode> resList = new ArrayList<>();\n\t\tfor (TreeNode parent : treeList) {\n\t\t\tif (PARENT_ID==parent.getParentId()) {\n\t\t\t\tresList.add(findChildren(parent, treeList));\n\t\t\t}\n\t\t}\n\t\treturn resList;\n\t}\n \n\tprivate  TreeNode findChildren(TreeNode parent, List<TreeNode> treeList) {\n\t\tfor (TreeNode child : treeList) {\n\t\t\tif (parent.getId().equals(child.getParentId())) {\n\t\t\t\tif (parent.getChildren() == null) {\n\t\t\t\t\tparent.setChildren(new ArrayList<>());\n\t\t\t\t}\n\t\t\t\tparent.getChildren().add(findChildren(child, treeList));\n\t\t\t}\n\t\t}\n\t\treturn parent;\n\t}\n``````\n \n","tags":["tree"]},{"title":"如何保障消息的可靠性传输","url":"%2F2019%2F07%2F14%2F%E5%A6%82%E4%BD%95%E4%BF%9D%E9%9A%9C%E6%B6%88%E6%81%AF%E7%9A%84%E5%8F%AF%E9%9D%A0%E6%80%A7%E4%BC%A0%E8%BE%93%2F","content":"> 摘要： 本文主要介绍如何保证消息的可靠性传输（如何处理消息丢失的问题）？\n\n\n1.丢数据，mq一般分为两种，要么是mq自己弄丢了，要么是我们消费的时候弄丢了。咱们从rabbitmq来分析一下吧\n\n1）生产者弄丢了数据\n\n生产者将数据发送到rabbitmq的时候，可能数据就在半路给搞丢了，因为网络啥的问题，都有可能。\n\n此时可以选择用rabbitmq提供的事务功能，就是生产者发送数据之前开启rabbitmq事务（channel.txSelect），然后发送消息，如果消息没有成功被rabbitmq接收到，那么生产者会收到异常报错，此时就可以回滚事务（channel.txRollback），然后重试发送消息；如果收到了消息，那么可以提交事务（channel.txCommit）。但是问题是，rabbitmq事务机制一搞，基本上吞吐量会下来，因为太耗性能。\n\n所以一般来说，如果你要确保说写rabbitmq的消息别丢，可以开启confirm模式，在生产者那里设置开启confirm模式之后，你每次写的消息都会分配一个唯一的id，然后如果写入了rabbitmq中，rabbitmq会给你回传一个ack消息，告诉你说这个消息ok了。如果rabbitmq没能处理这个消息，会回调你一个nack接口，告诉你这个消息接收失败，你可以重试。而且你可以结合这个机制自己在内存里维护每个消息id的状态，如果超过一定时间还没接收到这个消息的回调，那么你可以重发。\n\n事务机制和cnofirm机制最大的不同在于，事务机制是同步的，你提交一个事务之后会阻塞在那儿，但是confirm机制是异步的，你发送个消息之后就可以发送下一个消息，然后那个消息rabbitmq接收了之后会异步回调你一个接口通知你这个消息接收到了。\n\n所以一般在生产者这块避免数据丢失，都是用confirm机制的。\n\n2）rabbitmq弄丢了数据\n\n就是rabbitmq自己弄丢了数据，这个你必须开启rabbitmq的持久化，就是消息写入之后会持久化到磁盘，哪怕是rabbitmq自己挂了，恢复之后会自动读取之前存储的数据，一般数据不会丢。除非极其罕见的是，rabbitmq还没持久化，自己就挂了，可能导致少量数据会丢失的，但是这个概率较小。\n\n设置持久化有两个步骤，\n\n第一个是创建queue的时候将其设置为持久化的，这样就可以保证rabbitmq持久化queue的元数据，但是不会持久化queue里的数据；\n\t\n第二个是发送消息的时候将消息的deliveryMode设置为2，就是将消息设置为持久化的，此时rabbitmq就会将消息持久化到磁盘上去。\n\t\n必须要同时设置这两个持久化才行，rabbitmq哪怕是挂了，再次重启，也会从磁盘上重启恢复queue，恢复这个queue里的数据。\n\n而且持久化可以跟生产者那边的confirm机制配合起来，只有消息被持久化到磁盘之后，才会通知生产者ack了，所以哪怕是在持久化到磁盘之前，rabbitmq挂了，数据丢了，生产者收不到ack，你也是可以自己重发的。\n\n哪怕是你给rabbitmq开启了持久化机制，也有一种可能，就是这个消息写到了rabbitmq中，但是还没来得及持久化到磁盘上，结果不巧，此时rabbitmq挂了，就会导致内存里的一点点数据会丢失。\n\n3）消费端弄丢了数据\n\nrabbitmq如果丢失了数据，主要是因为你消费的时候，刚消费到，还没处理，结果进程挂了，比如重启了，那么就尴尬了，rabbitmq认为你都消费了，这数据就丢了。\n\n这个时候得用rabbitmq提供的ack机制，简单来说，就是你关闭rabbitmq自动ack，可以通过一个api来调用就行，然后每次你自己代码里确保处理完的时候，再程序里ack一把。这样的话，如果你还没处理完，不就没有ack？那rabbitmq就认为你还没处理完，这个时候rabbitmq会把这个消费分配给别的consumer去处理，消息是不会丢的。\n\n","tags":["消息"]},{"title":"全局唯一邀请码生生成","url":"%2F2019%2F06%2F29%2F%E5%85%A8%E5%B1%80%E5%94%AF%E4%B8%80%E9%82%80%E8%AF%B7%E7%A0%81%E7%94%9F%E7%94%9F%E6%88%90%2F","content":"> 摘要： 本文主要介绍全局唯一邀请码生生成。\n\n\n1.为什么需要邀请码\n-----------------\n无论什么APP需要做推广功能，而推广功能多多少少都离不开邀请码。被邀请用户下载APP登录时输入邀请码，邀请码所有者将获得一定的好处，比如积分奖励、现金奖励或者免费试用（VIP）等特权。一套优秀的邀请码生成机制不仅确保全局唯一性，还需要考虑到性能等问题\n\n\n\n2.邀请码的特性\n----------------\n唯一性：确保每个用户的邀请码都是独一无二的，这样系统才能判定谁为邀请者，甚至可以根据邀请码进行反向推导。\n随机性：不能让用户从邀请码上轻易的看出生成的规则。\n高效性：生成邀请码的算法不能过于复杂，或耗费过度系统资源。\n简洁性：用户可以方便的输入，记录，辨别是否输入错误等\n\n3.随机生成邀请码\n----------------\n无论是纯数字还是数字加大写字母形式，使用随机算法生成一个邀请码然后判断此随机码是否已经被使用，如果被使用则重新生成。这可能是最初步的思路，但此种方法弊端甚多。\n\n\n以6为随机数为例说明。6位随机数取0-9共10个数字，生成邀请码的范围为000000-999999，总数为10的6次方，也就是100万。试想一下，如果有50万的用户，那么采用随机数的生成，每次生成的重复概率将在50%以上，而且会越来越重复率越高，多么可怕的性能损耗。\n\n\n当然，在用户量比较少的情况下此种方法不是完全不可行。可以通过数据库或redis预先生成一批邀请码，当注册新用户或用户使用邀请码的时候将邀请码分配给对应的用户。此种补漏的方法虽然解决了一部分性能的问题，但从根本上还是需要消耗数据库或redis资源，时间维度和空间维度都有一定的损耗。\n\nbase编码方式实现\n----------------\n一般来说生成一个用户的邀请码需要一个唯一的输入参数，这里就用用户的ID（长整型数）来作为输入参数，输出结果为6为数字+大写字母。同时，通过邀请码可以反推出用户的ID。\n\n\n示例代码\n------------------\n\n``````\nimport java.util.Random;\n\n/**\n * 邀请码生成器，基本原理：<br/>\n * 1）入参用户ID：1 <br/>\n * 2）使用自定义进制转换之后为：V <br/>\n * 3）转换未字符串，并在后面添加'A'：VA <br/>\n * 4）在VA后面再随机补足4位，得到：VAHKHE <br/>\n * 5）反向转换时以'A'为分界线，'A'后面的不再解析 <br/>\n * \n */\npublic class ShareCodeUtil {\n\n\t/**\n\t * 自定义进制(0,1没有加入,容易与o,l混淆)，数组顺序可进行调整增加反推难度，A用来补位因此此数组不包含A，共31个字符。可扩展小写.\n\t */\n\tprivate static final char[] BASE = new char[] { 'H', 'V', 'E', '8', 'S', '2', 'D', 'Z', 'X', '9', 'C', '7', 'P',\n\t\t\t'5', 'I', 'K', '3', 'M', 'J', 'U', 'F', 'R', '4', 'W', 'Y', 'L', 'T', 'N', '6', 'B', 'G', 'Q' };\n\n\t/**\n\t * A补位字符，不能与自定义重复\n\t */\n\tprivate static final char SUFFIX_CHAR = 'A';\n\n\t/**\n\t * 进制长度\n\t */\n\tprivate static final int BIN_LEN = BASE.length;\n\n\t/**\n\t * 生成邀请码最小长度\n\t */\n\tprivate static final int CODE_LEN = 6;\n\n\t/**\n\t * ID转换为邀请码\n\t *\n\t * @param id\n\t * @return\n\t */\n\tpublic static String idToCode(Long id) {\n\t\tchar[] buf = new char[BIN_LEN];\n\t\tint charPos = BIN_LEN;\n\n\t\t// 当id除以数组长度结果大于0，则进行取模操作，并以取模的值作为数组的坐标获得对应的字符\n\t\twhile (id / BIN_LEN > 0) {\n\t\t\tint index = (int) (id % BIN_LEN);\n\t\t\tbuf[--charPos] = BASE[index];\n\t\t\tid /= BIN_LEN;\n\t\t}\n\n\t\tbuf[--charPos] = BASE[(int) (id % BIN_LEN)];\n\t\t// 将字符数组转化为字符串\n\t\tString result = new String(buf, charPos, BIN_LEN - charPos);\n\n\t\t// 长度不足指定长度则随机补全\n\t\tint len = result.length();\n\t\tif (len < CODE_LEN) {\n\t\t\tStringBuilder sb = new StringBuilder();\n\t\t\tsb.append(SUFFIX_CHAR);\n\t\t\tRandom random = new Random();\n\t\t\t// 去除SUFFIX_CHAR本身占位之后需要补齐的位数\n\t\t\tfor (int i = 0; i < CODE_LEN - len - 1; i++) {\n\t\t\t\tsb.append(BASE[random.nextInt(BIN_LEN)]);\n\t\t\t}\n\n\t\t\tresult += sb.toString();\n\t\t}\n\n\t\treturn result;\n\t}\n\n\t/**\n\t * 邀请码解析出ID<br/>\n\t * 基本操作思路恰好与idToCode反向操作。\n\t *\n\t * @param code\n\t * @return\n\t */\n\tpublic static Long codeToId(String code) {\n\t\tchar[] charArray = code.toCharArray();\n\t\tlong result = 0L;\n\t\tfor (int i = 0; i < charArray.length; i++) {\n\t\t\tint index = 0;\n\t\t\tfor (int j = 0; j < BIN_LEN; j++) {\n\t\t\t\tif (charArray[i] == BASE[j]) {\n\t\t\t\t\tindex = j;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (charArray[i] == SUFFIX_CHAR) {\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tif (i > 0) {\n\t\t\t\tresult = result * BIN_LEN + index;\n\t\t\t} else {\n\t\t\t\tresult = index;\n\t\t\t}\n\t\t}\n\n\t\treturn result;\n\n\t}\n\n\tpublic static void main(String[] args) {\n\t\tString code = idToCode(1L);\n\t\tSystem.out.println(code);\n\t\tSystem.out.println(codeToId(code));\n\t}\n\n}\n``````\n\n","tags":["ShareCodeUtil"]},{"title":"assert","url":"%2F2019%2F05%2F20%2Fassert%2F","content":"> 摘要： 本文主要介绍单点登录系统Junit的assert。\n----------------\n\n断言是编写测试用例的核心实现方式，即期望值是多少，测试的结果是多少，以此来判断测试是否通过。\n\n\n1. 断言核心方法 Assert\n\n\n   assertArrayEquals(expecteds, actuals)\t查看两个数组是否相等。\n\t\t\n   assertEquals(expected, actual)\t查看两个对象是否相等。类似于字符串比较使用的equals()方法\n\t\t\t\n   assertNotEquals(first, second)\t查看两个对象是否不相等。\n\t\t\t\n   assertNull(object)\t查看对象是否为空。\n\t\t\t\n   assertNotNull(object)\t查看对象是否不为空。\n\t\t\t\n   assertSame(expected, actual)\t查看两个对象的引用是否相等。类似于使用“==”比较两个对象\n\t\t\t\n   assertNotSame(unexpected, actual)\t查看两个对象的引用是否不相等。类似于使用“!=”比较两个对象\n\t\t\t\n   assertTrue(condition)\t查看运行结果是否为true。\n\t\t\t\n   assertFalse(condition)\t查看运行结果是否为false。\n\t\t\t\n   assertThat(actual, matcher)\t查看实际值是否满足指定的条件\n\t\t\t\n   fail()\t让测试失败\n\t\t\n2、Junit基本注解介绍\n\n   \n   //在所有测试方法前执行一次，一般在其中写上整体初始化代码 \n   \n   @BeforeClass\n    \n   //在所有测试方法后执行一次，一般在其中写上销毁和释放资源的代码 \n    \n   @AfterClass\n    \n   //在每个测试方法前执行，一般用来初始化方法（比如我们在测试别的方法时，类中与其他测试方法共享的值已经被改变，为了保证测试结果的有效性，我们会在@Before注解的方法中重置数据） \n    \n   @Before\n    \n   //在每个测试方法后执行，在方法执行完成后要做的事情 \n    \n   @After\n    \n   // 测试方法执行超过1000毫秒后算超时，测试将失败 \n    \n   @Test(timeout = 1000)\n    \n   // 测试方法期望得到的异常类，如果方法执行没有抛出指定的异常，则测试失败 \n    \n   @Test(expected = Exception.class)\n    \n   // 执行测试时将忽略掉此方法，如果用于修饰类，则忽略整个类 \n    \n   @Ignore(“not ready yet”) \n   \n   @Test\n    \n   @RunWith \n   \n   在JUnit中有很多个Runner，他们负责调用你的测试代码，每一个Runner都有各自的特殊功能，你要根据需要选择不同的Runner来运行你的测试代码。 \n    如果我们只是简单的做普通Java测试，不涉及Spring Web项目，你可以省略@RunWith注解，这样系统会自动使用默认Runner来运行你的代码。\n \n \n 3.项目中中如何使用Junit\n \n  创建测试类，在测试类中添加注解\n  \n  @RunWith(SpringRunner.class)\n  \n  @SpringBootTest(classes={xxApplication.class})//项目启动类\n\n","tags":["assert"]},{"title":"es 单机版集群搭建","url":"%2F2019%2F04%2F20%2Fes-%E5%8D%95%E6%9C%BA%E7%89%88%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA%2F","content":"\n> 摘要： 本文主要介绍es 单机版集群搭建。\n\nes 单机版集群搭建\n    \n  主要配置文件\n   --elasticsearch.yml es配置文件\n   --jvm.options jvm相关的配置 内存大小等等\n   --log4j2.properties 日志系统定义\n   es 集群 主从\n   head 插件-web管理器\n   logstash --数据库与Elasticsearch同步索引\n    \n集群搭建\n    \n   1 安装jdk\n   2 安装es 将es拷贝3份\n    \n   3 集群搭建demo、本机测试只需将192.168.35.124换成自己电脑ip即可\n    \n  master\n    \n    cluster.name: notice-application  # 集群名称集群节点cluster.name需一致\n    node.name: master   #节点名称\n    node.master: true\n    network.host: 192.168.35.124    # 当前节点的IP地址\n    # network.bind_host: 192.168.11.21\n    http.port: 9200  # 对外提供服务的端口，9300为集群服务\n    transport.tcp.port: 9300\n    discovery.zen.ping.unicast.hosts: [\"192.168.35.124:9300\",\"192.168.35.124:9310\",\"192.168.35.124:9320\"]\n    # 集群个节点IP地址\n    discovery.zen.minimum_master_nodes: 2    # 为了避免脑裂，集群节点数最少为 半数+1\n    \n    \n  slave1\n    \n    cluster.name: notice-application\n    node.name: slave1\n    # network.publish_host: 192.168.11.21\n    # network.bind_host: 192.168.11.21\n    network.host: 192.168.35.124\n    http.port: 9210\n    transport.tcp.port: 9310\n    discovery.zen.ping.unicast.hosts: [\"192.168.35.124:9300\",\"192.168.35.124:9310\",\"192.168.35.124:9320\"]\n    \n  slave2\n    \n    cluster.name: notice-application\n    node.name: slave2\n    # network.publish_host: 192.168.11.21\n    # network.bind_host: 192.168.11.21\n    network.host: 192.168.35.124\n    http.port: 9220\n    transport.tcp.port: 9320\n    discovery.zen.ping.unicast.hosts: [\"192.168.35.124:9300\",\"192.168.35.124:9310\",\"192.168.35.124:9320\"]\n    \n    \n  启动master、slave1、slave2 3个节点\n  \n  浏览器输入 http://192.168.35.124:9200/_cat/nodes?v 查看集群 显示如下：则集群搭建成功\n  \n  ![](/img/elasticsearch.png)\n  \n  \n  \n\n","tags":["elasticsearch"]},{"title":"Spring boot与Spring cloud","url":"%2F2019%2F03%2F13%2FSpring-boot%E4%B8%8ESpring-cloud%2F","content":"\n> 摘要：Spring boot与Spring cloud\n\n1、什么是Spring Boot\n---------------- \n\nSpring Boot是整合了框架的框架，它让一切依赖都变得有序简单，你不用操心A.jar是什么版本，又依赖哪些版本的jar，它默认配置了很多框架的使用方式，就像 maven整合了所有的jar包，Spring Boot整合了所有的框架，第三方库的功能你拿着就能用。\nSpring Boot的核心思想就是约定大于配置，一切由内定的约束来自动完成。采用 Spring Boot可以大大的简化你的开发模式，节省大部分照搬照抄的成本，通过少量的代码就能创建一个独立的，它都有对应的组件支持。\n\n它是由 Pivotal团队提供的全新框架,其设计目的是用来简化新 Spring应用的初始搭建以及开发过程。该框架使用了特定的方式来进行配置,从而使开发人员不再需要定义样板化的配置。\n\nSpring boot 是 Spring 的一套快速配置脚手架，可以基于spring boot 快速开发单个微服务，Spring Boot，看名字就知道是Spring的引导，就是用于启动Spring的，使得Spring的学习和使用变得快速无痛。不仅适合替换原有的工程结构，更适合微服务开发。\n\n\n\n以启动一个带Hibernate的Spring MVC为例。\n1. 依赖太多了，而且要注意版本兼容。这个应用，要添加10-20个依赖，Spring相关的包10多个，然后是Hibernate包，Spring与Hibernate整合包，日志包，json包一堆，而且要注意版本兼容性。\n\n2. 配置太多了，要配置注解驱动，要配置数据库连接池，要配置Hibernate，要配置事务管理器，要配置Spring MVC的资源映射，要在web.xml中配置启动Spring和Spring MVC等\n\n3.部署和运行麻烦。要部署到tomcat里面。不能直接用java命令运行。\n\n太多重复和大家都一样的配置了。\n\nSpring Boot的哲学就是约定大于配置。既然很多东西都是一样的，为什么还要去配置。\n\n1. 通过starter和依赖管理解决依赖问题。\n2. 通过自动配置，解决配置复杂问题。\n3. 通过内嵌web容器，由应用启动web容器，而不是web容器启动应用，来解决部署运行问题。\n\n2、什么是Spring Cloud\n---------------- \n\nSpring Cloud是一套分布式服务治理的框架,既然它是一套服务治理的框架，那么它本身不会提供具体功能性的操作，更专注于服务之间的通讯、熔断、监控等。因此就需要很多的组件来支持一套功能。\n微服务是可以独立部署、水平扩展、独立访问(或者有独立的数据库)的服务单元， Spring Cloud就是这些微服务的大管家，采用了微服务这种架构之后，项目的数量会非常多， Spring Cloud做为大管家就需要提供各种方案来维护整个生态。\n\nSpring Cloud基于Spring Boot，为微服务体系开发中的架构问题，提供了一整套的解决方案——服务注册与发现，服务消费，服务保护与熔断，网关，分布式调用追踪，分布式配置管理等。\n\nSpring Cloud是一个基于Spring Boot实现的云应用开发工具；Spring boot专注于快速、方便集成的单个个体，Spring Cloud是关注全局的服务治理框架；spring boot使用了默认大于配置的理念，很多集成方案已经帮你选择好了，能不配置就不配置，Spring Cloud很大的一部分是基于Spring boot来实现。\n\n\n3、Spring boot与Spring cloud 之间的关系\n---------------- \n\n你可以把spring boot的官方的包分为两类，一种是为了搭建一个服务用的，比如hibernate jpa，比如 message。另外一种含有cloud关键字的，是为了各个spring boot之前管理和使用的包。\n\n因为当把集群、CI等方法集中进来一起考虑的时候，这件事情就复杂了。\n\n多个小有服务整合成的大服务，要有一个消息总线来用于互相通知和调用，要有一个服务发现程序来管理某个小服务上线可用，同时在服务离线时也要能处理，各个小服务要尽量各自独立，还要考虑服务的依赖性，集群的负载均衡，配置文件的分离。\n\n再把CI和Docker拿进来一起考虑的话，更乱。\n\n但我认为这样完成的一个服务是更具有可插拔性，更容易维护的。而且遵循了上面的cloud方案的话，在服务的健壮性上面也很强。\n\n写到这里对于新接触的我认为可以先从单独的spring boot程序开始入门，当要添加一个新功能时，考虑拆分成另外服务。两个程序间可以通过 jmx或是 其它消息中间件或是rest通讯。最后实现了一个各自独立的功能集群。\n\n总结一句：Spring boot可以离开Spring Cloud独立使用开发项目，但是Spring Cloud离不开Spring boot，属于依赖的关系\n\n\nSpringCloud是Spring为微服务架构思想做的一个一站式实现。从某种程度是可以简单的理解为，微服务是一个概念、一个项目开发的架构思想。SpringCloud是微服务架构的一种java实现。\nSpringCloud是基于SpringBoot的一套实现微服务的框架。它提供了微服务开发所需的配置管理、服务发现、断路器、智能路由、微代理、控制总线、全局锁、决策竞选、分布式会话和集群状态管理等组件。最重要的是，跟SpringBoot框架一起使用的话，会让你开发微服务架构的云服务非常方便。\n\nSpringCloud核心组件\n\n```\n\t\n\t消息总线  - Spring cloud Bus\n\t配置中心分布式配置 - spring cloud config\n\t服务注册发现-Netflix Eureka\n\t负载均衡-Netflix Ribbon\n\t断路器 - Netflix Hystrix\n\t路由(服务网关) - Netflix Zuul\n\t服务调用  - Netflix Feign\n\t\n```\n\n","tags":["Spring boot"]},{"title":"Token Auth","url":"%2F2019%2F03%2F02%2FToken-Auth%2F","content":"\n> 摘要：Token\n\n1、Token简介\n---------------- \nToken 是一种权限认证机制，在服务端不需要存储用户的登陆记录。\n\n2、Token流程\n----------------\n\n（1）客户端使用name password 请求登陆\n\n（2）服务端接收请求，去验证name password\n\n（3）验证成功会，服务端会签发一个Token 在把这个Token发送给服务端\n\n（4）客户端收到Token 并把它存储起来，如放入header、Cookie\n\n（5）客户端每次向服务端请求资源时需要携带服务端签发的Token\n\n（6）服务端收到请求，然后去验证客户端请求里携带的Token，验证成功，返回客户端请求的资源\n\n2、Token Auth 的优点\n----------------\n\n支持跨域访问: Cookie是不允许垮域访问的，这一点对Token机制是不存在的，前提是传输的用户认证信息通过HTTP头传输.\n\n无状态(也称：服务端可扩展行):Token机制在服务端不需要存储session信息，因为Token 自身包含了所有登录用户的信息，只需要在客户端的cookie或本地介质存储状态信息.\n\n更适用CDN: 可以通过内容分发网络请求你服务端的所有资料（如：javascript，HTML,图片等），而你的服务端只要提供API即可.\n\n去耦: 不需要绑定到一个特定的身份验证方案。Token可以在任何地方生成，只要在你的API被调用的时候，你可以进行Token生成调用即可.\n\n更适用于移动应用: 当你的客户端是一个原生平台（iOS, Android，Windows 8等）时，Cookie是不被支持的（你需要通过Cookie容器进行处理），这时采用Token认证机制就会简单得多。\n\nCSRF:因为不再依赖于Cookie，所以你就不需要考虑对CSRF（跨站请求伪造）的防范。\n\n性能: 一次网络往返时间（通过数据库查询session信息）总比做一次HMACSHA256计算 的Token验证和解析要费时得多.\n\n不需要为登录页面做特殊处理: 如果你使用Protractor 做功能测试的时候，不再需要为登录页面做特殊处理.\n\n基于标准化:你的API可以采用标准化的 JSON Web Token (JWT). 这个标准已经存在多个后端库（.NET, Ruby, Java,Python, PHP）和多家公司的支持（如：Firebase,Google, Microsoft）.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","tags":["Token"]},{"title":"MongoDB 入门","url":"%2F2019%2F02%2F15%2FMongoDB-%E5%85%A5%E9%97%A8%2F","content":"\n> 摘要：文档型数据库MongoDB\n\n\n[MongoDB菜鸟教程](http://www.runoob.com/mongodb/mongodb-tutorial.html)\n\n[MongoDB官网](https://www.mongodb.com/)\n\n1、MongoDB简介\n---------------- \n\n（1）数据量大\n\n（2）写入操作频繁\n\n（3）价值较低\n\n对于这样的数据，我们更适合使用MongoDB来实现数据的存储\n\n1.2、什么是MongoDB\n---------------- \n\nMongoDB 是一个跨平台的，面向文档的数据库，是当前 NoSQL 数据库产品中最热\n门的一种。它介于关系数据库和非关系数据库之间，是非关系数据库当中功能最丰富，最像关\n系数据库的产品。它支持的数据结构非常松散，是类似 JSON 的 BSON 格式，因此可以\n存储比较复杂的数据类型。\n\n1.3、MongoDB特点\n---------------- \n\nMongoDB 最大的特点是他支持的查询语言非常强大，其语法有点类似于面向对象\n的查\n询语言，几乎可以实现类似关系数据库单表查询的绝大部分功能，而且还支持对数据建 立索\n引。它是一个面向集合的,模式自由的文档型数据库。\n具体特点总结如下：\n\n（1）面向集合存储，易于存储对象类型的数据\n\t（2）模式自由\n\t（3）支持动态查询\n\t（4）支持完全索引，包含内部对象\n\t（5）支持复制和故障恢复\n\t（6）使用高效的二进制数据存储，包括大型对象（如视频等）\n\t（7）自动处理碎片，以支持云计算层次的扩展性\n\t（8）支持 Python，PHP，Ruby，Java，C，C#，Javascript，Perl 及 C++语言的驱动程序，\n    社区中也提供了对 Erlang 及.NET 等平台的驱动程序\n    （9）文件存储格式为 BSON（一种 JSON 的扩展）\n1.4、MongoDB体系结构\n---------------- \n\nMongoDB   的逻辑结构是一种层次结构。主要由：\n文档(document)、集合(collection)、数据库(database)这三部分组成的。逻辑结构是面 向用户的，用户使用 MongoDB 开发应用程序使用的就是逻辑结构。\n（1）MongoDB 的文档（document），相当于关系数据库中的一行记录。\n（2）多个文档组成一个集合（collection），相当于关系数据库的表。\n（3）多个集合（collection），逻辑上组织在一起，就是数据库（database）。\n（4）一个 MongoDB 实例支持多个数据库（database）。\n文档(document)、集合(collection)、数据库(database)的层次结构如下图:\n\n![](/img/imgs/mongodb层次结构.png)\n\n\n下表是MongoDB与MySQL数据库逻辑结构概念的对比\n    \n | MongoDb\t| 关系型数据库Mysql |\n | ------------- |:-------------:| \n | 数据库(databases) | 数据库(databases) |\n | 集合(collections)\t| 表(table) |\n | 文档(document)\t| 行(row) |\n\n1.5、数据类型\n---------------- \n\n基本数据类型\n\nnull：用于表示空值或者不存在的字段，{“x”:null}\n布尔型：布尔类型有两个值true和false，{“x”:true}\n数值：shell默认使用64位浮点型数值。{“x”：3.14}或{“x”：3}。对于整型值，可以使用\nNumberInt（4字节符号整数）或NumberLong（8字节符号整数），\n{“x”:NumberInt(“3”)}{“x”:NumberLong(“3”)}\n字符串：UTF-8字符串都可以表示为字符串类型的数据，{“x”：“呵呵”}\n日期：日期被存储为自新纪元依赖经过的毫秒数，不存储时区，{“x”:new Date()}\n\n正则表达式：查询时，使用正则表达式作为限定条件，语法与JavaScript的正则表达式相 同，{“x”:/[abc]/}\n数组：数据列表或数据集可以表示为数组，{“x”： [“a“，“b”,”c”]}\n内嵌文档：文档可以嵌套其他文档，被嵌套的文档作为值来处理，{“x”:{“y”:3 }}\n对象Id：对象id是一个12字节的字符串，是文档的唯一标识，{“x”: objectId() }\n二进制数据：二进制数据是一个任意字节的字符串。它不能直接在shell中使用。如果要 将非utf-字符保存到数据库中，二进制数据是唯一的方式。\n代码：查询和文档中可以包括任何JavaScript代码，{“x”:function(){/…/}}\n\n2、走进MongoDB\n---------------- \n\n2.1、MongoDB安装与启动\n\nDocker 环境下MongoDB的安装\n\n[Docker 安装MongoDB](http://www.runoob.com/docker/docker-install-mongodb.html)\n\nMongoDB 常用命令\n\n选择和创建数据库 ：\n\n    use DATABASE_NAME\n查看所有数据库 ：\n\n    show dbs\n插入和查询文档 ：\n\n插入\n\n    db.COLLECTION_NAME.insert(document)\n查询\n    \n    db.COLLECTION_NAME.find(query, projection)\n>> query ：可选，使用查询操作符指定查询条件\n\n>> projection ：可选，使用投影操作符指定返回的键。查询时返回文档中所有键值， 只需省略该参数即可（默认省略）。\n  \n  返回符合条件的第一条数据 \n  \n    db.COLLECTION_NAME.findOne()\n  \n  返回指定条数的记录 \n  \n    db.COLLECTION_NAME.find().limit(n)\n  \n修改和删除文档 \n修改\n\n    db.COLLECTION_NAME.update(条件,修改后的数据)\n 删除\n    \n    db.col.remove(条件)   \n    db.col.remove({}) //删除所有数据\n 统计条数\n    \n    db.col.count()\nJava 操作MongoDB\n\n[MongoDB Java](http://www.runoob.com/mongodb/mongodb-java.html)\n\n","tags":["MongoDB"]},{"title":"Snowflake 算法","url":"%2F2019%2F02%2F13%2FSnowflake-%E7%AE%97%E6%B3%95%2F","content":">摘要：Snowflake算法\n\n1、twitter雪花算法的原理\n------------------\n\ntwitter的雪花算法，是将id按二进制比特位切割，不同的位区间，表示不同的含义，也即是不同位区间\n\n的值生成方式不同，从而生成唯一的id。\n\n如位区间可分为时间位区间、集群位区间、机器位区间、自增位区间，这样可在不同时间内、不同集群、\n\n不同机器间，生成全局唯一的id。\n\n\n\n2、twitter雪花算法的实例\n------------------\n\n\n在此以生成64位（即Long型）为例进行介绍（其实区间位可以根据具体的业务需要自行指定）。\n\n1、位区间化分\n\n0 - 41位时间戳 - 5位数据中心标识 - 5位机器标识 - 12位序列号\n\n最高位（即第64位，从右向左数）为符号位，不使用；\n\n41位（第23位到第63位）为时间位，精确到毫秒级，可使用个数为2199023255551个，以毫秒为单位，大约69.5年；可以根据时间进行排序；\n\n5位（第18位到第22位）为集群位，可使用个数为32个；\n\n5位（第13位到第17位）为机器位，可使用个数为32个；\n\n12位（第1位到第12位）为序列号位，即是从0开始自增，可使用个数为4096个；\n\n2、确定时间位开始计算的时间点\n\n本例以2017-10-12 00:00:00开始计时，那么过去掉的时间（从1970-01-01 00:00:00开始）的毫秒数\n\n为1507737600000，取时间时需要减去这段时间。\n\n\n3、示例代码\n------------------\n\n``````\n\nimport java.lang.management.ManagementFactory;\nimport java.net.InetAddress;\nimport java.net.NetworkInterface;\nimport java.util.concurrent.ExecutorService;\nimport java.util.concurrent.Executors;\n\n/**\n * 分布式自增长ID\n * Twitter的 Snowflake　JAVA实现方案\n *\n * 核心代码为其IdWorker这个类实现，其原理结构如下，分别用一个0表示一位，用—分割开部分的作用：\n * 1||0---0000000000 0000000000 0000000000 0000000000 0 --- 00000 ---00000 ---000000000000\n * 在上面的字符串中，第一位为未使用（实际上也可作为long的符号位），接下来的41位为毫秒级时间，\n * 然后5位datacenter标识位，5位机器ID（并不算标识符，实际是为线程标识），\n * 然后12位该毫秒内的当前毫秒内的计数，加起来刚好64位，为一个Long型。\n * 这样的好处是，整体上按照时间自增排序，并且整个分布式系统内不会产生ID碰撞（由datacenter和机器ID作区分），\n * 并且效率较高，经测试，snowflake每秒能够产生26万ID左右。\n *\n * 64位ID (42(毫秒)+5(机器ID)+5(业务编码)+12(重复累加))\n *\n * @author Search\n */\npublic class IdWorker {\n\n    // 时间起始标记点，作为基准，一般取系统的最近时间（系统时钟依赖性,一旦确定不能变动）\n    private final static long twepoch = 1288834974657L;\n    // 机器标识位数\n    private final static long workerIdBits = 5L;\n    // 数据中心标识位数\n    private final static long datacenterIdBits = 5L;\n    // 机器ID最大值\n    private final static long maxWorkerId = -1L ^ (-1L << workerIdBits);\n    // 数据中心ID最大值\n    private final static long maxDatacenterId = -1L ^ (-1L << datacenterIdBits);\n    // 毫秒内自增位\n    private final static long sequenceBits = 12L;\n    // 机器ID偏左移12位\n    private final static long workerIdShift = sequenceBits;\n    // 数据中心ID左移17位\n    private final static long datacenterIdShift = sequenceBits + workerIdBits;\n    // 时间毫秒左移22位\n    private final static long timestampLeftShift = sequenceBits + workerIdBits + datacenterIdBits;\n\n    private final static long sequenceMask = -1L ^ (-1L << sequenceBits);\n    /* 上次生产id时间戳 */\n    private static long lastTimestamp = -1L;\n    // 0，并发控制\n    private long sequence = 0L;\n\n    private final long workerId;\n    // 数据标识id部分\n    private final long datacenterId;\n\n    public IdWorker(){\n        this.datacenterId = getDatacenterId(maxDatacenterId);\n        this.workerId = getMaxWorkerId(datacenterId, maxWorkerId);\n    }\n    /**\n     * @param workerId\n     *            工作机器ID\n     * @param datacenterId\n     *            序列号\n     */\n    public IdWorker(long workerId, long datacenterId) {\n        if (workerId > maxWorkerId || workerId < 0) {\n            throw new IllegalArgumentException(String.format(\"worker Id can't be greater than %d or less than 0\", maxWorkerId));\n        }\n        if (datacenterId > maxDatacenterId || datacenterId < 0) {\n            throw new IllegalArgumentException(String.format(\"datacenter Id can't be greater than %d or less than 0\", maxDatacenterId));\n        }\n        this.workerId = workerId;\n        this.datacenterId = datacenterId;\n    }\n    /**\n     * 获取下一个ID\n     *\n     * @return\n     */\n    public synchronized long nextId() {\n        long timestamp = timeGen();\n        if (timestamp < lastTimestamp) {\n            throw new RuntimeException(String.format(\"Clock moved backwards.  Refusing to generate id for %d milliseconds\", lastTimestamp - timestamp));\n        }\n\n        if (lastTimestamp == timestamp) {\n            // 当前毫秒内，则+1\n            sequence = (sequence + 1) & sequenceMask;\n            if (sequence == 0) {\n                // 当前毫秒内计数满了，则等待下一秒\n                timestamp = tilNextMillis(lastTimestamp);\n            }\n        } else {\n            sequence = 0L;\n        }\n        lastTimestamp = timestamp;\n        // ID偏移组合生成最终的ID，并返回ID\n        long nextId = ((timestamp - twepoch) << timestampLeftShift)\n                | (datacenterId << datacenterIdShift)\n                | (workerId << workerIdShift) | sequence;\n\n        return nextId;\n    }\n\n    private long tilNextMillis(final long lastTimestamp) {\n        long timestamp = this.timeGen();\n        while (timestamp <= lastTimestamp) {\n            timestamp = this.timeGen();\n        }\n        return timestamp;\n    }\n\n    private long timeGen() {\n        return System.currentTimeMillis();\n    }\n\n    /**\n     * 获取 maxWorkerId\n     * @param datacenterId\n     * @param maxWorkerId\n     * @return\n     */\n    protected static long getMaxWorkerId(long datacenterId, long maxWorkerId) {\n        StringBuffer mpid = new StringBuffer();\n        mpid.append(datacenterId);\n        String name = ManagementFactory.getRuntimeMXBean().getName();\n        if (!name.isEmpty()) {\n         /*\n          * GET jvmPid\n          */\n            mpid.append(name.split(\"@\")[0]);\n        }\n      /*\n       * MAC + PID 的 hashcode 获取16个低位\n       */\n        return (mpid.toString().hashCode() & 0xffff) % (maxWorkerId + 1);\n    }\n\n    /**\n     * 数据标识 id 部分\n     * @param maxDatacenterId\n     * @return\n     */\n    protected static long getDatacenterId(long maxDatacenterId) {\n        long id = 0L;\n        try {\n            InetAddress ip = InetAddress.getLocalHost();\n            NetworkInterface network = NetworkInterface.getByInetAddress(ip);\n            if (network == null) {\n                id = 1L;\n            } else {\n                byte[] mac = network.getHardwareAddress();\n                id = ((0x000000FF & (long) mac[mac.length - 1])\n                        | (0x0000FF00 & (((long) mac[mac.length - 2]) << 8))) >> 6;\n                id = id % (maxDatacenterId + 1);\n            }\n        } catch (Exception e) {\n            System.out.println(\" getDatacenterId: \" + e.getMessage());\n        }\n        return id;\n    }\n\n    public static void main(String[] args) {\n        final IdWorker idGenerator = new IdWorker(1, 1);\n        // 线程池并行执行10000次ID生成\n\n        ExecutorService executorService = Executors.newCachedThreadPool();\n        for (int i = 0; i < 10000; i++) {\n            executorService.execute(new Runnable() {\n                @Override\n                public void run() {\n                    long id = idGenerator.nextId();\n                    System.out.println(id);\n                }\n            });\n        }\n        executorService.shutdown();\n    }\n}\n``````\n","tags":["Snowflake"]},{"title":"前后端API交互如何保证安全性","url":"%2F2019%2F01%2F06%2F%E5%89%8D%E5%90%8E%E7%AB%AFAPI%E4%BA%A4%E4%BA%92%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E5%AE%89%E5%85%A8%E6%80%A7%2F","content":"> 摘要： 本文主要介绍前后端API交互如何保证安全性\n\n1.为什么要保证安全性\n-----------------\n前后端分离的开发方式，以接口为标准进行推动，定义好接口后，各自开发自己的功能，最后进行联调整合。无论是原生app的开发还是webapp的开发\n还是pc软件，只要是前后端分离模式的软件，就避免不了调用后端接口进行数据交互。\n\n不安全的接口，通过网络，只要进行抓包就可以清楚地知道请求的数据，如果是敏感信息，稍有不慎就会被不法分子盗用。\n\n2.如何保证API调用数据时的安全性\n----------------\n1、通信时使用https协议\n\n2、请求签名，防止参数被修改\n\n3、身份确认机制，每次请求都要验证身份是否合法\n\n4、对所有的请求和响应都进行加解密操作\n\n等等","tags":["安全"]},{"title":"【Netty】NIO 编程","url":"%2F2018%2F12%2F24%2F%E3%80%90Netty%E3%80%91NIO-%E7%BC%96%E7%A8%8B%2F","content":"> 摘要：主要介绍NIO 编程\n\n网络编程的基本模型是client/server 模型（两个进程之间的相互通信） 服务端提供位置信息/绑定ip地址和监听端口）客户端通过连接操作向服务器监听的地址发送连接请求，通过三次握手建立通信，如连接成功 则通过网络套接字/socket/通信。\n\n基于传统同步阻塞模型开发中，serverSocket 负责绑定ip 地址，启动监听端口，socket 负责发起连接操作。连接成功之后，双方通过输入输出流进行同步阻塞式通信。\n   \n1.BIO通信模型图\n----------------   \n![](/img/imgs/同步阻塞io服务端通信模型.jpg)  \n\n\n采用BIO 通信模型的服务端，通常由一个独立的Acceptor 线程负责监听客户端的连接，它接收到客户端连接请求之后为每个客户端创建一个新的线程进行链路处理，处理完成后，通过输出流返回应答给客户段，线程销毁。\n\n该模型缺乏弹性伸缩能力，当客户端并发并访问量增加，服务端的线程个数和客户端访问呈1：1 相关，由于线程是Java虚拟机的宝贵资源，当线程数膨胀后，系统的性能将急剧下降，随着并发访问增大，系统会发生堆栈溢出 创建新线程失败，最终导致进程宕机或者僵死，不能对外提供服务\n\n\n\n\n\n>1、BIO 的主要问题在于每当有一个新的客户端请求接入时，服务端必须创建一个新的线程处理新接入的客户端链路，一个线程只能处理一个客户端连接，在高性能服务器应用领域，需要面对上万个客户端的并发连接，无法满足高性能高并发接入的场景\n\n>2、为了改进一线程一连接模型，通过线程池或者消息队列实现，一个或者多个线程处理n个客户端的模型，由于它的底层通信机制依然使用同步阻塞IO，所以被称为伪异步，\n\n2.伪异步IO编程\n------------------\n\n后端通过一个线程池来处理多个客户端的请求接入，客户端个数M 线程池最大线程数N，通过线程池灵活调配线程资源，设置线程的最大值，防止并发接入导致线程耗尽，\n\n伪异步IO模型图\n![](/img/imgs/asyn-io.png)  \n当有新的客户端接入的时候，将客户端的Socket封装成一个Task（该任务实现java.lang.Runnable接口）投递到后端的线程池中进行处理,JDK的线程池维护一个消息队列和N个活跃线程对消息队列中的任务进行处理。由于线程池可以设置消息队列的大小和最大线程数，因此，它的资源占用是可控的，无论多少个客户端并发访问，都不会导致资源的耗尽和宕机。 \n\n\n\n\n伪异步IO通信框架采用了线程池实现，因此避免了为每个请求都创建一个独立线程造成的线程资源耗尽问题。但是由于它底层的通信依然采用同步阻塞模型，因此无法从根本上解决问题。\n伪异步IO弊端分析\n\n3.NIO编程\n--------------\nNIO提供SocketChannel和 ServerSocketChannel不同的套接字通道实现;\n通常 低负载 低并发的应用选择同步阻塞IO降低复杂度  高并发 高负载选择NIO 的非阻塞式模式\n\nNIO类库简介\n\t\n1缓冲区buffer\n\t\n2通道channel\n\t\n3多复用selector\n\t\n4.NIO服务端序列图\n-------------------\n![](/img/imgs/NIO服务端序列图.png)  \n\n\n\nNIO客户端序列图\n![](/img/imgs/NIO客户端序列图.png) \n\nNIO的优点\n\t\n1. 不需要使用read()或者write()操作就可以处理文件内容了\n\n2. 修改文件后，修改自动flush到文件\n\n3. nio方式能很快处理大文件和处理效率很快\n\n\n4种IO的对比\n\n不同IO模型对比\n\n总结\n\tIO的编程和使用差异，对比各自的缺点，给出使用建议对netty进行分析和总结\n\n\n","tags":["Netty"]},{"title":"【Netty】为什么选择Netty","url":"%2F2018%2F12%2F24%2F%E3%80%90Netty%E3%80%91%E4%B8%BA%E4%BB%80%E4%B9%88%E9%80%89%E6%8B%A9Netty%2F","content":"\n> 摘要：主要介绍选择Netty 的理由\n\n1.不选择Java 原生NIO 编程的原因\n----------------\nNIO 的类库和API 繁杂，使用麻烦，你需要熟练掌握Selector，ServerSocketChannel，SocketChannel，ByteBuffer 等。\n\n需要其他技能做铺垫，如熟悉Java 多线程编程。这是应为NIO 编程涉及Reactor 模式，你必须对多线程和网络编程非常熟悉，才能写出高质量的NIO 程序。\n\n可靠性能力不齐，工作量和难度大。比如客户端面临断连重连，网络闪断，半包读写，失败缓存，网络拥塞，异常码流等问题。NIO 开发的特点是功能开发相对简单，但可靠性不强，工作量大。\n\nJDK NIO 的bug，如epoll bug 会导致Selector 空轮询，最终导致CPU 100%。\n\n2.为什么选择Netty\n----------------\nnetty 是业界最流行的NIO 框架之一，它的健壮性 功能 性能 可定制性和可扩展性在同类框架中都是首屈一指的\n\tnetty优点：\n\t\napi简单 开发门槛低。\n\n功能强大 预置了多种编解码功能，支持多种主流协议。\n\n定制能力强，可以通过channelHandler对通信框架进行灵活扩展。\n\n性能高，通过与其他业界主流的NIO 框架对比 ，netty 的综合性能最优。\n\n成熟 稳定，netty修复了已经发现的所有jdk NIO bug ，业务人员不需要在为NIO 的bug 而烦恼。\n\n社区活跃，版本迭代周期短，发现的bug 可以被及时修复，更多的新功能也会加入。\n\n经历了大规模的商业应用的检验，质量得到验证，netty 在互联网 大数据 网络游戏 企业应用 电信软件等众多行业中得到成功商用。\n","tags":["Netty"]},{"title":"【短信验证】短信验证码流程","url":"%2F2018%2F12%2F20%2F%E3%80%90%E7%9F%AD%E4%BF%A1%E9%AA%8C%E8%AF%81%E3%80%91%E7%9F%AD%E4%BF%A1%E9%AA%8C%E8%AF%81%E7%A0%81%E5%AE%9E%E7%8E%B0%2F","content":"> 摘要： 本文主要介绍短信验证码。\n\n1.为什么需要验证码\n-----------------\n\n短信验证码用于保护网站。试想一下，如果有人使用作弊设备，在您的网站上多次注册，登录，发布和评论不仅会严重影响网站的运行，导致网站缓慢打开，还会导致大量垃圾内容，这将不可避免地导致网站体验。如果平台用户的注册不再需要输入手机验证码，商务平台每天将受到不同的攻击，运营和维护成本将大幅增加，并且使用用户移动互联网将大大减少。垃圾邮件的影响和规模将无法预测。对于平台，服务器资源是有限的。如果有人恶意登录，或使用软件发送垃圾邮件，则会导致服务器崩溃并最终拖动平台。因此，在网站的操作中，需要添加短信验证码功能。\n\n其次，短信验证码是由商家向用户发出的用于验证身份的证书。短信验证码平台通过手机短信发送验证码，这是验证用户真实身份的最常用，最安全的方式。通过手机号码验证注册会员，您可以确认手机号码属于我。提高网站用户注册的质量，并可以更有效地管理网站的注册用户。通过手机验证码，商家可以更方便地获取用户信息，并与他们进行交互，随时与他们保持联系和沟通。第三，用户的手机号码也可以绑定，派生出更多的短信验证码应用。例如手机密码恢复，登录保护，交易确认，手机发送指令，手机账号和用户注册账号等可以同步登录，同步通讯录，同步更多手机相关应用。短信验证码的使用有效提高了用户账号的安全性，是电子商务和行业网站不可或缺的一部分。高质量的短信验证码对于改善用户体验具有不可替代的作用。\n\n\n2.短信验证流程\n----------------\n\n1、构造手机验证码，如生成一个6位的随机数字串；\n\n2、正则验证手机号，使用接口向短信平台发送手机号和验证码，然后短信平台再把验证码发送到指定的手机号上；\n\n3、将手机号、验证码、操作时间存入Session中，作为后面验证使用；\n\n4、接收用户填写的验证码、手机号及其他注册数据，提交；\n\n5、对比提交的验证码与Session中的验证码是否一致，同时判断提交动作是否在有效期内；\n\n6、验证码正确且在有效期内，请求通过，处理相应的业务\n\n","tags":["短信验证"]},{"title":"【Javaweb】购物车实现","url":"%2F2018%2F12%2F15%2F%E3%80%90Javaweb%E3%80%91%E8%B4%AD%E7%89%A9%E8%BD%A6%E5%AE%9E%E7%8E%B0%2F","content":"\n1.购物车实现方式\n---------------------------\n1.用cookie实现购物车；\n\t\n2.用session实现购物车；\n\t\n3.用cookie和数据库(购物车信息持久化)实现购物车；\n\t\n----\n\t\n1.单纯有cookie实现购物车，这样的购物车不是很理想，设想一下，如果客户端的浏览器把cookie给禁用了...\n\n2.session中保存购物车的信息，这个只是在一个会话中可用，如果用户没有登录，或者说登录了以后，添加购物车，在关闭浏览器...\n\n2.分析\n---------------------------\n1、添加购物车不需要用户登录。购物车的数据应该放到cookie中。\n\n2、当向购物车添加同一款商品时，购物车中商品的数量增加。\n\n3、购物车中可以删除商品\n\n4、购物车中可以修改商品数量。商品的总价需要重新计算。\n\n5、点击“结算”按钮要求用户登录。\n\n3.实现\n---------------------------\nA.用户登录前的数据流：用户在没有登录系统的时候，对喜欢的商品进行添加购物车，那么这个时候，我们可以把购物车信息保存到cookie中，这里会涉及到cookie的添加，修改操作；也即如果之前在cookie中不存对应的cookie，则就对cookie进行添加操作。\n\n如果在cookie中存在对应的cookie，那么，这时候，就要对cookie进行修改操作了(这里涉及到用户对同一个商品进行多次添加购物车的情况)。\n\nB.用户登录后的数据流：用户在登录后，系统首先做的第一件事就是去获取对应的cookies，如果存在相关的购物车cookies，那么就对该购物车信息进行相应用户User的持久化操作，要么添加，要么修改。（添加操作:该用户所对应的购物车如果没有相应的信息进行添加操作；修改操作：类似的，\n\n如果存在对应用户的购物车信息，就进行修改操作）。用户登录后，也可以进行购物车的添加操作，不过，这里不是添加到cookie中，而是直接持久化到数据库中。注：用户登录后的数据都是和数据库打交道。\n\n\n","tags":["cart"]},{"title":"【Java】线程","url":"%2F2018%2F12%2F15%2F%E3%80%90Java%E3%80%91%E7%BA%BF%E7%A8%8B%2F","content":"\n> 摘要：主要介绍线程\n\n1.进程和线程的区别\n----------------\n进程是具有一定独立功能的程序关于某个数据集合上的一次运行活动，是系统进行资\n源分配和调度的一个独立单位。\n\t\n线程是进程的一个实体，是CPU 调度和分派的基本单位，他是比进程更小的能独立运\n行的基本单位，线程自己基本上不拥有系统资源，只拥有一点在运行中必不可少的资源（如\n程序计数器，一组寄存器和栈），一个线程可以创建和撤销另一个线程；\n\t\n>1.1进程和线程的关系：\n----------------\n①一个线程只能属于一个进程，而一个进程可以有多个线程，但至少有一个线程。\n\n②资源分配给进程，同一进程的所有线程共享该进程的所有资源。\n\n③线程在执行过程中，需要协作同步。不同进程的线程间要利用消息通信的办法实现同步。\n\n④处理机分给线程，即真正在处理机上运行的是线程。\n\n⑤线程是指进程内的一个执行单元，也是进程内的可调度实体。\n\n>1.2线程与进程的区别：\n----------------\n\n①调度：线程作为调度和分配的基本单位，进程作为拥有资源的基本单位。\n\n②并发性：不仅进程之间可以并发执行，同一个进程的多个线程之间也可以并发执行。\n\n③拥有资源：进程是拥有资源的一个独立单位，线程不拥有系统资源，但可以访问隶属于进\n\t程的资源。\n\t\n④系统开销：在创建或撤销进程的时候，由于系统都要为之分配和回收资源，导致系统的明\n\t显大于创建或撤销线程时的开销。但进程有独立的地址空间，进程崩溃后，在保护模式下不\n\t会对其他的进程产生影响，而线程只是一个进程中的不同的执行路径。线程有自己的堆栈和\n\t局部变量，但线程之间没有单独的地址空间，一个线程死掉就等于整个进程死掉，所以多进\n\t程的程序要比多线程的程序健壮，但是在进程切换时，耗费的资源较大，效率要差些。\n\t线程的划分尺度小于进程，使得多线程程序的并发性高。另外，进程在执行过程中拥有\n\t独立的内存单元，而多个线程共享内存，从而极大的提高了程序运行效率。\n\t线程在执行过程中，每个独立的线程有一个程序运行的入口，顺序执行序列和程序的出\n\t口。但是线程不能够独立执行，必须依存在应用程序中，有应用程序提供多个线程执行控制。\n\t从逻辑角度看，多线程的意义子啊与一个应用程序中，有多个执行部分可以同时执行。但操\n\t作系统并没有将多个线程看做多个独立的应用，来实现进程的调度和管理以及资源分配。这\n\t就是进程和线程的重要区别。\n\t\n2.出现死锁的条件\n----------------\n出现死锁有4 个必要条件：\n\n①互斥：存在互斥使用的资源，也就是临界资源；\n\n②占有等待：拥有资源的进程都在等待另外的资源；\n\n③非剥夺：进行所占有的资源是不可剥夺使用的资源；\n\n④循环等待：都在相互等待资源。\n\t\n3.多线程中stop 为什么不合适\n----------------\n多线程之间一般是有联系的，若用stop 停止了线程，容易强行打断线程之间的联系，\n\t容易产生错误。\n4.Sleep 和wait 的区别\n----------------\n①sleep 是Thread 类中的，wait 是Object 中的；\n\n②sleep 会在指定时间之后自动唤醒，wait 需要其他线程调用notify 或者notifyAll 唤醒；\n\n③sleep 还有个最大的特点就是谁调用，谁睡觉，即使在a 类中调用b 的sleep 方法，实际上还是a 去睡觉。\n\n④wait 只能使用在同步控制方法或者同步控制块中使用，sleep 在任何地方都能被使用；\n\n⑤持有锁的线程执行sleep，不释放锁，持有锁的线程执行到wait（）时锁释放。\n5.线程的五个状态和特点\n----------------\n①新建状态(New)：新创建了一个线程对象。\n\n②就绪状态(Runnable)：线程对象创建后,其他线程调用了该对象的start()方法.该状态的线程位于可运行线程池中,变得可运行,等待获取CPU 的使用权.\n\n③运行状态(Running)：就绪状态的线程获取了CPU,执行程序代码.\n\n④阻塞状态(Blocked)：阻塞状态是线程因为某种原因放弃CPU 使用权,暂时停止运行.\n\t直到线程进入就绪状态,才有机会转到运行状态.阻塞的情况分三种：A）等待阻塞：运行的线程执\n\t行wait()方法,JVM 会把该线程放入等待池中。B）同步阻塞：运行的线程在获取对象的同步锁时，若该同步锁被别的线程占用,则JVM 会把该线程放入锁池中。 C）其他阻塞：\n\t运行的线程执行sleep()或join()方法,或者发出了I/O 请求时,JVM 会把该线程置为阻塞状态.当sleep()状态超时 join()等待线程终止或者超时 或者I/O 处理完毕时,线程重新转入就绪状态.\n\n⑤死亡状态(Dead)：线程执行完了或者因异常退出了run()方法,该线程结束生命周\n期.\n\n\n\n\n6.线程的生命周期\n----------------\n\n![](/img/线程生命周期.jpg)\n\n7.什么情况下使用Thread 什么情况下使用Runnable\n----------------\n继承Thread 类：如果一个类有了父类，便无法再继承。实现Runnale：更灵活，没\n有单继承的局限。\t","tags":["thread"]},{"title":"【Java】开发过程中的内存溢出及解决办法","url":"%2F2018%2F12%2F15%2F%E3%80%90Java%E3%80%91%E5%BC%80%E5%8F%91%E8%BF%87%E7%A8%8B%E4%B8%AD%E7%9A%84%E5%86%85%E5%AD%98%E6%BA%A2%E5%87%BA%E5%8F%8A%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95%2F","content":"\n\n> 摘要： 本文主要是对开发过程中存在的内存溢出问题及解决办法。\n\n1.引起内存溢出的原因有很多种，常见如下：\n----------------\n1. 内存中加载的数据量过于庞大，如一次从库取出多数据;\n2. 集合类中有对对象的引用，使完后未清空，使得JVM 不能回收;\n3. 代码中存在死循环或循环产生过多重复的对象实体; \n4. 使用的 第三方软件中的BUG;\n5. 启动参数内存值设定的过小;\n\n2.内存溢出的解决方案： \n----------------\n\n第一步，修改 JVM 启动参数，直接增加内存。（-Xms,Xmx参数不要忘记加）\n\n第二步，检查错误日志，查看‘outOfMemory’错误前是否有其它异常或错误。\n\n第三步，对代码进行走查和分析，找出可能发生内存溢出的位置。\n\n\n1. 检查对数据库询中，是否有一次获得全部的数据。一般来说如果一次取十万条记录到内存就可能引起内存溢出。这个问题比较隐蔽，在上线前，数据库中数据较少，不容易出现问题，上线后，数据库中数据增多，一次查询可能引起内存溢出。因此对于数据库查询尽可能采用分页的方式查询。\n2. 检查代码中是否有死循环或递归调用。\n3. 检查是否有大循环重复产生新对象实体。\n4. 检查List、Map 等集合对象是否有使用完后未清除的问题。List、Map 等集合对象会始终存有对对象的引用，使得这些对象不能被GC 回收。\n\n第四步，使用内存查看工具动态查看内存使用情况。\n\n```\n\n\n\n\n\n","tags":["Java"]},{"title":"【分布式】单点登录系统","url":"%2F2018%2F12%2F15%2F%E3%80%90SSO%E3%80%91%E5%8D%95%E7%82%B9%E7%99%BB%E5%BD%95%E7%B3%BB%E7%BB%9F%2F","content":"> 摘要： 本文主要介绍单点登录系统。\n\n1.什么是单点登录系统\n----------------\nSSO英文全称Single Sign On，单点登录。SSO是在多个应用系统中，用户只需要登录一次就可以访问所有相互信任的应用系统。它包括可以将这次主要的登录映射到其他应用中用于同一个用户的登录的机制。它是目前比较流行的企业业务整合的解决方案之一。\n SSO单点登录系统就是使用redis模拟Session（Key-Value），实现Session的统一管理。\n\n2.创建单点登录系统\n----------------\n使用的技术：\n----------------\n1、Mybatis\n\n2、Spring\n\n3、Springmvc\n\n4、Jedis\n\n## 具体实现\nSSO表现层\n        定义了三个处理器，分别用于注册、登录、外部调用，查看用户登录状态：\t\n \t\n## 登录拦截器\n分析\n当用户提交订单时此时必须要求用户登录，可以使用拦截器来实现。\n拦截器的处理流程：\n----------------\n1、拦截请求url\n\n2、从cookie中取token\n\n3、如果没有toke跳转到登录页面。\n\n4、取到token，需要调用sso系统的服务查询用户信息。\n\n5、如果用户session已经过期，跳转到登录页面\n\n6、如果没有过期，放行。\n \t","tags":["SSO"]},{"title":"【分布式】分布式环境中三种Session管理方法的使用场景及优缺点","url":"%2F2018%2F10%2F14%2F%E3%80%90Session%E3%80%91%E5%88%86%E5%B8%83%E5%BC%8F%E7%8E%AF%E5%A2%83%E4%B8%AD%E4%B8%89%E7%A7%8DSession%E7%AE%A1%E7%90%86%E6%96%B9%E6%B3%95%E7%9A%84%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF%E5%8F%8A%E4%BC%98%E7%BC%BA%E7%82%B9%2F","content":"\n在分布式环境，管理Session通常使用下面三种方式：\n\n一、Session Replication 方式管理 (即session复制)\n------------------------------------------------\n\n简介：将一台机器上的Session数据广播复制到集群中其余机器上\n\n使用场景：机器较少，网络流量较小\n\n优点：实现简单、配置较少、当网络中有机器Down掉时不影响用户访问\n\n缺点：广播式复制到其余机器有一定廷时，带来一定网络开销\n\n二、Session Sticky 方式管理\n---------------------------\n\n简介：即粘性Session、当用户访问集群中某台机器后，强制指定后续所有请求均落到此机器上\n\n使用场景：机器数适中、对稳定性要求不是非常苛刻\n\n优点：实现简单、配置方便、没有额外网络开销\n\n缺点：网络中有机器Down掉时、用户Session会丢失、容易造成单点故障\n\n三、缓存集中式管理\n------------------\n\n简介：将Session存入分布式缓存集群中的某台机器上，当用户访问不同节点时先从缓存中拿Session信息\n\n使用场景：集群中机器数多、网络环境复杂\n\n优点：可靠性好\n\n缺点：实现复杂、稳定性依赖于缓存的稳定性、Session信息放入缓存时要有合理的策略写入\n\n","tags":["Session"]}]